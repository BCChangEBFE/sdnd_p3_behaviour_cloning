{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Behaviour Cloning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The dataset provided in project description is used. \n",
    "Flipped images are also generated with the flipped entries in the .csv, so the data set is twice as big."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First define some testing veriables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n"
     ]
    }
   ],
   "source": [
    "test_on_small_data = False\n",
    "#test_on_small_data = True\n",
    "\n",
    "#resize_image = False\n",
    "resize_image = True\n",
    "\n",
    "print(\"start\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "\n",
    "Start by importing the data from the pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Image\n",
      "shape x_all: (18232, 160, 320, 3)\n",
      "shape y_all: (18232,)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import scipy.misc as misc\n",
    "\n",
    "#CUDA_VISIBLE_DEVICES=1\n",
    "\n",
    "if test_on_small_data:\n",
    "    data_folder = \"small_data\"\n",
    "else:\n",
    "    data_folder = \"data\"\n",
    "\n",
    "print(\"Loading Image\")\n",
    "data_file = os.path.join(data_folder,\"data.p\")\n",
    "with open(data_file, mode='rb') as f:\n",
    "    all_data = pickle.load(f, encoding='latin1')\n",
    "    #all_data = pickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "split_test_validation_set = False\n",
    "\n",
    "y_train = np.array(all_data[\"results\"])\n",
    "x_train = np.array(all_data[\"features\"])\n",
    "##reshape the image into 160x320\n",
    "#x_train = []\n",
    "#for i in range(len(all_data[\"features\"])):\n",
    "#    x_train.append(misc.imresize(all_data[\"features\"][i],(160,320)))\n",
    "#x_train = np.array(x_train)\n",
    "\n",
    "\n",
    "print(\"shape x_all:\", x_train.shape)\n",
    "print(\"shape y_all:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def regression_train_test_split(x_train, y_train, \n",
    "                                random_state = False, test_size = 0.25, \n",
    "                                min_y = -1, max_y = 1, groups = 10 ):\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    groupped_x = []\n",
    "    groupped_y = []\n",
    "    step_size = (max_y - min_y)/groups\n",
    "    for g in range(groups):\n",
    "        groupped_x.append([])\n",
    "        groupped_y.append([])\n",
    "    for i in range(len(y_train)):\n",
    "        for g in range(groups):\n",
    "            #min_y_bound = min_y + step_size*g\n",
    "            max_y_bound = max_y - step_size*(groups-(g+1))\n",
    "            if y_train[i] <= max_y_bound:\n",
    "                groupped_x[g].append(x_train[i])\n",
    "                groupped_y[g].append(y_train[i])\n",
    "                break\n",
    "\n",
    "    for g in range(groups):\n",
    "        #print(g, np.array(groupped_x[g]).shape, np.array(groupped_y[g]).shape)\n",
    "        if random_state:\n",
    "            tmp_x_train, tmp_x_test, tmp_y_train, tmp_y_test = train_test_split(\n",
    "                                                                            np.array(groupped_x[g]),\n",
    "                                                                            np.array(groupped_y[g]),\n",
    "                                                                            test_size=test_size,\n",
    "                                                                            random_state=random_state)\n",
    "        else:\n",
    "            tmp_x_train, tmp_x_test, tmp_y_train, tmp_y_test = train_test_split(\n",
    "                                                                            np.array(groupped_x[g]),\n",
    "                                                                            np.array(groupped_y[g]),\n",
    "                                                                            test_size=test_size)\n",
    "        if g == 0:\n",
    "            x_train = tmp_x_train\n",
    "            x_test = tmp_x_test\n",
    "            y_train = tmp_y_train\n",
    "            y_test = tmp_y_test\n",
    "        else:\n",
    "            x_train = np.concatenate((x_train,tmp_x_train))\n",
    "            x_test = np.concatenate((x_test,tmp_x_test))\n",
    "            y_train = np.concatenate((y_train,tmp_y_train))\n",
    "            y_test = np.concatenate((y_test,tmp_y_test))\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into Train/Validation/Testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Before Splitting =========\n",
      "shape of x_train,  (18232, 160, 320, 3)\n",
      "shape of y_train,  (18232,)\n",
      "========= After Splitting  =========\n",
      "shape of x_train,  (11662, 160, 320, 3)\n",
      "shape of y_train,  (11662,)\n",
      "shape of x_valid,  (2920, 160, 320, 3)\n",
      "shape of y_valid,  (2920,)\n",
      "shape of x_test,  (3650, 160, 320, 3)\n",
      "shape of y_test,  (3650,)\n"
     ]
    }
   ],
   "source": [
    "print(\"========= Before Splitting =========\")\n",
    "print(\"shape of x_train, \",x_train.shape)\n",
    "print(\"shape of y_train, \",y_train.shape)\n",
    "\n",
    "if not split_test_validation_set:\n",
    "    if test_on_small_data:\n",
    "        print(\"testing on small data set\")\n",
    "        x_test = x_train\n",
    "        x_valid = x_train\n",
    "        y_test = y_train\n",
    "        y_valid = y_train\n",
    "    else:\n",
    "        x_train, x_test, y_train, y_test = regression_train_test_split(x_train,y_train,\n",
    "                                                                    #random_state=10,\n",
    "                                                                    test_size=0.2)\n",
    "        x_train, x_valid, y_train, y_valid = regression_train_test_split(x_train,y_train, \n",
    "                                                                    #random_state=10,\n",
    "                                                                    test_size=0.2)\n",
    "\n",
    "print(\"========= After Splitting  =========\")\n",
    "print(\"shape of x_train, \",x_train.shape)\n",
    "print(\"shape of y_train, \",y_train.shape)\n",
    "print(\"shape of x_valid, \",x_valid.shape)\n",
    "print(\"shape of y_valid, \",y_valid.shape)\n",
    "print(\"shape of x_test, \",x_test.shape)\n",
    "print(\"shape of y_test, \",y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Transfer Learning with AlexNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_train = x_train.shape[0]\n",
    "n_test = x_test.shape[0]\n",
    "n_valid = x_valid.shape[0]\n",
    "\n",
    "input_shape = x_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "####################################\n",
    "# Training Parameters\n",
    "training_epochs = 22\n",
    "batch_size = 128\n",
    "dropout_rate = 0.50\n",
    "learning_rate = 0.005\n",
    "####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from alexnet import AlexNet\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Flatten, MaxPooling2D, Convolution2D\n",
    "from keras.layers.core import Dense, Dropout, Activation, Reshape, Lambda, ActivityRegularization\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "custom layer for resizing image to speed up training, \n",
    "Not used as saving of custom layer does not work (https://github.com/fchollet/keras/issues/2435)\n",
    "example Usage:\n",
    "    model.add( MyResizeImg(output_dim = (32,64,3)) )\n",
    "'''\n",
    "class MyResizeImg(Layer):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        super(MyResizeImg, self).__init__(**kwargs)\n",
    "         \n",
    "    def call(self, x, mask=None):\n",
    "        return tf.image.resize_images(x, self.output_dim[0:2], method=0, align_corners=False)\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        output_shape = (input_shape[0], *self.output_dim)\n",
    "        return output_shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_1 (Lambda)                (None, 80, 160, 3)    0           lambda_input_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)                (None, 80, 160, 3)    0           lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 80, 160, 24)   1824        lambda_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 40, 80, 24)    0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_1 (BatchNorma (None, 40, 80, 24)    48          maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 40, 80, 36)    21636       batchnormalization_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 20, 40, 36)    0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_2 (BatchNorma (None, 20, 40, 36)    72          maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 20, 40, 48)    43248       batchnormalization_2[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 10, 20, 48)    0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_3 (BatchNorma (None, 10, 20, 48)    96          maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 10, 20, 64)    27712       batchnormalization_3[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_4 (MaxPooling2D)    (None, 5, 10, 64)     0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 5, 10, 76)     43852       maxpooling2d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_5 (MaxPooling2D)    (None, 2, 5, 76)      0           convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 760)           0           maxpooling2d_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 1164)          885804      flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 100)           116500      dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 100)           0           dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 50)            5050        dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 10)            510         dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 1)             11          dense_4[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 1146363\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "if resize_image:\n",
    "    model.add(Lambda(lambda x: K.tf.image.resize_images(x, (80,160)), input_shape=input_shape))\n",
    "    model.add(Lambda(lambda x: x*1.8/255.0 - 1.))\n",
    "else:\n",
    "    model.add(Lambda(lambda x: x*1.8/255.0 - 1., input_shape=input_shape))\n",
    "\n",
    "#model.add(BatchNormalization())\n",
    "    \n",
    "#hidden layer 1\n",
    "model.add(Convolution2D(24, 5,5,\n",
    "                        border_mode='same',\n",
    "                        activation='elu',\n",
    "                        init='he_normal'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "#hidden layer 2\n",
    "model.add(Convolution2D(36, 5,5, \n",
    "                        border_mode='same',\n",
    "                        activation='elu',\n",
    "                        init='he_normal'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "#hidden layer 3\n",
    "model.add(Convolution2D(48, 5,5, \n",
    "                        border_mode='same',\n",
    "                        activation='elu',\n",
    "                        init='he_normal'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#hidden layer 4\n",
    "model.add(Convolution2D(64, 3,3, \n",
    "                        border_mode='same',\n",
    "                        activation='elu',\n",
    "                        init='he_normal'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "#model.add(BatchNormalization())\n",
    "\n",
    "#hidden layer 5\n",
    "model.add(Convolution2D(76, 3,3, \n",
    "                        border_mode='same',\n",
    "                        activation='elu',\n",
    "                        init='he_normal'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "#model.add(BatchNormalization())\n",
    "\n",
    "#hidden layer 6\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1164, activation='elu', init='he_normal'))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add((Dropout(dropout_rate)))\n",
    "\n",
    "#hidden layer 7\n",
    "model.add(Dense(100, activation='elu', init='he_normal'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add((Dropout(dropout_rate)))\n",
    "\n",
    "#hidden layer 8\n",
    "model.add(Dense(50, activation='elu', init='he_normal'))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add((Dropout(dropout_rate)))\n",
    "\n",
    "#hidden layer 9\n",
    "model.add(Dense(10, activation='elu', init='he_normal'))\n",
    "#model.add(BatchNormalization())\n",
    "\n",
    "#output layer\n",
    "model.add(Dense(1, activation='elu', init='he_normal'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.summary()\n",
    "\n",
    "#init = tf.initialize_all_variables()\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "filepath=\"model.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start\n",
      "Train on 11662 samples, validate on 2920 samples\n",
      "Epoch 1/22\n",
      "11648/11662 [============================>.] - ETA: 0s - loss: 0.1918Epoch 00000: val_loss improved from inf to 0.01641, saving model to model.h5\n",
      "11662/11662 [==============================] - 344s - loss: 0.1916 - val_loss: 0.0164\n",
      "Epoch 2/22\n",
      "11648/11662 [============================>.] - ETA: 0s - loss: 0.0207Epoch 00001: val_loss did not improve\n",
      "11662/11662 [==============================] - 344s - loss: 0.0207 - val_loss: 0.0196\n",
      "Epoch 3/22\n",
      "11648/11662 [============================>.] - ETA: 0s - loss: 0.0158Epoch 00002: val_loss improved from 0.01641 to 0.01159, saving model to model.h5\n",
      "11662/11662 [==============================] - 347s - loss: 0.0158 - val_loss: 0.0116\n",
      "Epoch 4/22\n",
      "11648/11662 [============================>.] - ETA: 0s - loss: 0.0134Epoch 00003: val_loss improved from 0.01159 to 0.01052, saving model to model.h5\n",
      "11662/11662 [==============================] - 349s - loss: 0.0134 - val_loss: 0.0105\n",
      "Epoch 5/22\n",
      "11648/11662 [============================>.] - ETA: 0s - loss: 0.0132Epoch 00004: val_loss did not improve\n",
      "11662/11662 [==============================] - 348s - loss: 0.0132 - val_loss: 0.0121\n",
      "Epoch 6/22\n",
      "11648/11662 [============================>.] - ETA: 0s - loss: 0.0123Epoch 00005: val_loss improved from 0.01052 to 0.00943, saving model to model.h5\n",
      "11662/11662 [==============================] - 351s - loss: 0.0123 - val_loss: 0.0094\n",
      "Epoch 7/22\n",
      "11648/11662 [============================>.] - ETA: 0s - loss: 0.0136Epoch 00006: val_loss did not improve\n",
      "11662/11662 [==============================] - 348s - loss: 0.0136 - val_loss: 0.0096\n",
      "Epoch 8/22\n",
      "11648/11662 [============================>.] - ETA: 0s - loss: 0.0115Epoch 00007: val_loss improved from 0.00943 to 0.00936, saving model to model.h5\n",
      "11662/11662 [==============================] - 346s - loss: 0.0116 - val_loss: 0.0094\n",
      "Epoch 9/22\n",
      "11648/11662 [============================>.] - ETA: 0s - loss: 0.0135Epoch 00008: val_loss did not improve\n",
      "11662/11662 [==============================] - 348s - loss: 0.0135 - val_loss: 0.0107\n",
      "Epoch 10/22\n",
      "11648/11662 [============================>.] - ETA: 0s - loss: 0.0112Epoch 00009: val_loss did not improve\n",
      "11662/11662 [==============================] - 347s - loss: 0.0112 - val_loss: 0.0124\n",
      "Epoch 11/22\n",
      "11648/11662 [============================>.] - ETA: 0s - loss: 0.0101Epoch 00010: val_loss did not improve\n",
      "11662/11662 [==============================] - 348s - loss: 0.0101 - val_loss: 0.0094\n",
      "Epoch 12/22\n",
      "11648/11662 [============================>.] - ETA: 0s - loss: 0.0100Epoch 00011: val_loss did not improve\n",
      "11662/11662 [==============================] - 350s - loss: 0.0100 - val_loss: 0.0107\n",
      "Epoch 13/22\n",
      "11648/11662 [============================>.] - ETA: 0s - loss: 0.0096Epoch 00012: val_loss improved from 0.00936 to 0.00832, saving model to model.h5\n",
      "11662/11662 [==============================] - 348s - loss: 0.0096 - val_loss: 0.0083\n",
      "Epoch 14/22\n",
      "11648/11662 [============================>.] - ETA: 0s - loss: 0.0092Epoch 00013: val_loss did not improve\n",
      "11662/11662 [==============================] - 349s - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 15/22\n",
      "11648/11662 [============================>.] - ETA: 0s - loss: 0.0093Epoch 00014: val_loss did not improve\n",
      "11662/11662 [==============================] - 351s - loss: 0.0093 - val_loss: 0.0096\n",
      "Epoch 16/22\n",
      "11648/11662 [============================>.] - ETA: 0s - loss: 0.0089Epoch 00015: val_loss did not improve\n",
      "11662/11662 [==============================] - 351s - loss: 0.0089 - val_loss: 0.0091\n",
      "Epoch 17/22\n",
      "11648/11662 [============================>.] - ETA: 0s - loss: 0.0088Epoch 00016: val_loss improved from 0.00832 to 0.00769, saving model to model.h5\n",
      "11662/11662 [==============================] - 350s - loss: 0.0088 - val_loss: 0.0077\n",
      "Epoch 18/22\n",
      "11648/11662 [============================>.] - ETA: 0s - loss: 0.0085Epoch 00017: val_loss did not improve\n",
      "11662/11662 [==============================] - 350s - loss: 0.0085 - val_loss: 0.0092\n",
      "Epoch 19/22\n",
      "11648/11662 [============================>.] - ETA: 0s - loss: 0.0078Epoch 00018: val_loss improved from 0.00769 to 0.00768, saving model to model.h5\n",
      "11662/11662 [==============================] - 348s - loss: 0.0078 - val_loss: 0.0077\n",
      "Epoch 20/22\n",
      "11648/11662 [============================>.] - ETA: 0s - loss: 0.0079Epoch 00019: val_loss did not improve\n",
      "11662/11662 [==============================] - 347s - loss: 0.0079 - val_loss: 0.0086\n",
      "Epoch 21/22\n",
      "11648/11662 [============================>.] - ETA: 0s - loss: 0.0077Epoch 00020: val_loss improved from 0.00768 to 0.00766, saving model to model.h5\n",
      "11662/11662 [==============================] - 351s - loss: 0.0077 - val_loss: 0.0077\n",
      "Epoch 22/22\n",
      "11648/11662 [============================>.] - ETA: 0s - loss: 0.0070Epoch 00021: val_loss did not improve\n",
      "11662/11662 [==============================] - 347s - loss: 0.0070 - val_loss: 0.0079\n",
      "3650/3650 [==============================] - 44s    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.008694195951500984"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_accuracy = 0.0\n",
    "\n",
    "\n",
    "print(\"training start\")\n",
    "# Launch the graph\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    callbacks=callbacks_list, \n",
    "                    batch_size=batch_size, nb_epoch=training_epochs,\n",
    "                    verbose=1, validation_data=(x_valid, y_valid))\n",
    "\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Accuracy:** (fill in here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## save model\n",
    "from keras.models import load_model\n",
    "import json\n",
    "\n",
    "with open('model.json', 'w') as outfile:\n",
    "    json_model = model.to_json()\n",
    "    json.dump(json_model, outfile)\n",
    "    outfile.close()\n",
    "\n",
    "#model.save('model.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design Notes and Obervatinos\n",
    "\n",
    "\n",
    "The source of the training data comes from udacity at (https://d17h27t6h515a5.cloudfront.net/topher/2016/December/584f6edd_data/data.zip)\n",
    "\n",
    "### Data \n",
    "\n",
    "The data is first duplicated by flipping each center-camera vertically and negating the steering angle to generate a second set of data. Data is then pickled as data.p.\n",
    "\n",
    "- The code to generate the flipped image is flip_jpg.py\n",
    "- The code to generate the flipped data pooints to be appended to driving_log.csv is flip_csv.py\n",
    "- The code to pickle the data is make_pickle.py\n",
    "\n",
    "### Preprocessing\n",
    "Input images are normalized linearly to be betwen -0.9 and 0.9.\n",
    "\n",
    "\n",
    "### Network Architecture\n",
    "\n",
    "The architecture of the network is mostly based on the Nvidia paper \"End to End Learning for Self-Driving Cars\" (https://arxiv.org/pdf/1604.07316v1.pdf)\n",
    "\n",
    "The Network consists of 9 layers, \n",
    " - layer 1: Convolution Layer depth of 24 and max pooling factor of 2. Followed by batch normalization.\n",
    " - layer 2: Convolution Layer depth of 36 and max pooling factor of 2. Followed by batch normalization.\n",
    " - layer 3: Convolution Layer depth of 48 and max pooling factor of 2. Followed by batch normalization.\n",
    " - layer 4: Convolution Layer depth of 64 and max pooling factor of 2.\n",
    " - layer 5: Convolution Layer depth of 64 and max pooling factor of 2.\n",
    " - layer 6: Fully Connected Flat layer with 1164 nodes. With a dropout of 50%\n",
    " - layer 7: Fully Connected Flat layer with 100 nodes.\n",
    " - layer 8: Fully Connected Flat layer with 10 nodes.\n",
    " - layer 9: Fully Connected Output layer with 1 nodes.\n",
    "\n",
    "### Tuning and Some Observations\n",
    "\n",
    "For some of the more difficult spots with sharper turns, data is duplicated a few more times (4 to 10 times) untill reasonable results are obtained.\n",
    "\n",
    "1. elu activiation seems to help the network to train faster as compared to relu.  \n",
    "2. he_normalization seems to result in a better performance.\n",
    "3. Including some batch_normalizaion layers in the earlier layers also result in a better performance. Including batch_normalization in later layers actually seems to make things worse.\n",
    "4. During my test runs, it seems that adding drop out layer to one of the more heavy layers (5 or 6) helps prevent over fitting. But adding to layer 7 or 8 seems to really slow down the training. \n",
    "5. While testing the model and observing the effects of tuning various parameters, smaller image size is used to speed up the process. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:keras]",
   "language": "python",
   "name": "conda-env-keras-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
